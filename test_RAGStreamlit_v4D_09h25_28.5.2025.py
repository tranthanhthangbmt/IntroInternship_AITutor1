#versions:
# test_RAGStreamlit_v3_10h56_27.5.2025.py s·ª≠a l·∫°i audio cho streamlit local
#test_RAGStreamlit_v3C_15h13_27.5.2025.py s·ª≠ l·∫°i ph·∫ßu t·∫£i file RAG t·ª´ Google Drive
#test_RAGStreamlit_v4_22h13_27.5.2025.py: hu·∫•n luy·ªán ti·∫øng Anh, h·ªèi b·∫±ng ti·∫øng Vi·ªát
#test_RAGStreamlit_v4A_24h49_28.5.2025.py: th√™m history messages c·ªßa m·ªói l·∫ßn ng∆∞·ªùi d√πng prompt
#test_RAGStreamlit_v4C_09h09_28.5.2025.py: th√™m CrossEncoder/ms-marco-MiniLM-L-6-v2, ch·ªâ c√≥ m·ªói vi
#test_RAGStreamlit_v4D_09h25_28.5.2025.py: b·ªï xung th√™n en,vn trong rank
#---------------------------
#run: streamlit run test_RAGStreamlit_v4D_09h25_28.5.2025.py
#run2: streamlit run --server.fileWatcherType none test_RAGStreamlit_v4D_09h25_28.5.2025.py
#------------------

# import os
# os.environ["STREAMLIT_WATCH_FILE_SYSTEM"] = "false"
import asyncio
try:
    asyncio.get_running_loop()
except RuntimeError:
    asyncio.set_event_loop(asyncio.new_event_loop())
    
import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from google.generativeai import GenerativeModel, configure

#audio
import edge_tts
#from modules.audio_module import generate_and_encode_audio
from modules.audio_module import render_audio_block

# Th√™m th∆∞ vi·ªán v√† h√†m rerank_with_crossencoder
from sentence_transformers import CrossEncoder

def shorten_passage(text, max_char=1200, overlap=200):
    if len(text) <= max_char:
        return [text]
    chunks = []
    start = 0
    while start < len(text):
        end = min(start + max_char, len(text))
        chunks.append(text[start:end].strip())
        start += max_char - overlap
    return chunks

def rerank_with_crossencoder(query, docs, model_name="cross-encoder/ms-marco-MiniLM-L-6-v2"):
    model = CrossEncoder(model_name)
    scored_docs = []
    for doc in docs:
        parts = shorten_passage(doc.page_content)
        for part in parts:
            score = model.predict([(query, part)])[0]
            scored_docs.append((score, part))
    ranked = sorted(scored_docs, key=lambda x: x[0], reverse=True)
    return ranked

# def rerank_with_crossencoder(query, docs, model_name="cross-encoder/ms-marco-MiniLM-L-6-v2"):
#     model = CrossEncoder(model_name)
#     scored_docs = []
#     for doc in docs:
#         score = model.predict([(query, doc.page_content)])[0]
#         scored_docs.append((score, doc.page_content))
#     ranked = sorted(scored_docs, key=lambda x: x[0], reverse=True)
#     return ranked

def summarize_chat_history(history, max_turns=3):
    if not history:
        return ""

    recent_turns = history[-max_turns:]
    summary = ""
    for turn in recent_turns:
        summary += f"Sinh vi√™n: {turn['question']}\n"
        summary += f"Tutor: {turn['answer']}\n"
    return summary.strip()

# ‚ö†Ô∏è C·∫•u h√¨nh API key Gemini (thay b·∫±ng key th·ª±c t·∫ø ho·∫∑c d√πng dotenv)
#configure(api_key="AIzaSyB23c7ttZ-RWiqj9O4dY82NutHsjz0N45s")

import streamlit as st
from google.generativeai import configure

configure(api_key=st.secrets["GEMINI_API_KEY"])
if "GEMINI_API_KEY" not in st.secrets:
    st.error("‚ùå Thi·∫øu kh√≥a API Gemini. Vui l√≤ng khai b√°o trong Settings > Secrets.")
    st.stop()

# import time

# long_text = "Xin ch√†o, t√¥i l√† Tutor AI..." * 30  # t·∫°o ƒëo·∫°n d√†i
# start = time.time()
# b64 = generate_and_encode_audio(long_text)
# print("Th·ªùi gian t·∫°o √¢m:", time.time() - start)

# Kh·ªüi t·∫°o model Gemini
model = GenerativeModel("models/gemini-2.0-flash-lite")

import os
import gdown

# T·∫°o ƒëo·∫°n m√£ Python t·∫£i th∆∞ m·ª•c FAISS t·ª´ Google Drive
# if not os.path.exists("IntroInternshipRAG_MiniLM_L3_withEbooks/faiss_index"):
#     gdown.download_folder(
#         url="https://drive.google.com/drive/folders/1GZF0Aas4n7m1kkd-MmoCGyR7oH77xXWE",
#         output="IntroInternshipRAG_MiniLM_L3_withEbooks",
#         quiet=False,
#         use_cookies=False
#     )

DATA_OUTPUT_FOLDER = "IntroInternshipRAG_MiniLM_L3_allRef"
if not os.path.exists(DATA_OUTPUT_FOLDER + "/faiss_index"):
    gdown.download_folder(
        url="https://drive.google.com/drive/folders/13tzW43t7MuqtOP8-xYy-7lRYgEgtNTVX",
        output=DATA_OUTPUT_FOLDER,
        quiet=False,
        use_cookies=False
    )

# D√πng m√¥ h√¨nh nh·ªè h∆°n
embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-MiniLM-L3-v2")

# Load FAISS index t·ª´ th∆∞ m·ª•c m·ªõi
#DATA_OUTPUT_FOLDER = "IntroInternshipRAG_MiniLM_L3_allRef"

vectorstore = FAISS.load_local(
    #"IntroInternshipRAG_MiniLM_L3/faiss_index",
    DATA_OUTPUT_FOLDER+ "/faiss_index",
    embeddings=embedding,
    allow_dangerous_deserialization=True
)


# C·∫•u h√¨nh giao di·ªán Streamlit
st.set_page_config(page_title="Tutor AI ‚Äì H·ªó tr·ª£ Th·ª±c t·∫≠p CNTT", page_icon="üéì")
st.set_option("client.showErrorDetails", False)
# Sidebar ‚Äì hi·ªÉn th·ªã logo v√† th√¥ng tin
with st.sidebar:
    st.image("https://raw.githubusercontent.com/tranthanhthangbmt/AITutor_Gemini/main/LOGO_UDA_2023_VN_EN_chuan2.png", width=180)
    if "enable_audio_playback" not in st.session_state:
        st.session_state["enable_audio_playback"] = False  # m·∫∑c ƒë·ªãnh b·∫≠t
    
    st.session_state["enable_audio_playback"] = st.sidebar.checkbox(
        "üîä T·ª± ƒë·ªông ph√°t √¢m thanh",
        value=st.session_state["enable_audio_playback"]
    )

    st.markdown("""
    ### üéì Tutor AI ‚Äì ƒê·∫°i h·ªçc ƒê√¥ng √Å
    **Tr·ª£ l√Ω ·∫£o ƒë·ªìng h√†nh c√πng sinh vi√™n nƒÉm 2 trong k·ª≥ th·ª±c t·∫≠p nh·∫≠n th·ª©c ng√†nh C√¥ng ngh·ªá Th√¥ng tin t·∫°i doanh nghi·ªáp**
    
    üí° B·∫°n s·∫Ω ƒë∆∞·ª£c h·ªó tr·ª£ v·ªÅ:
    - N·ªôi dung, y√™u c·∫ßu v√† l·ªãch tr√¨nh th·ª±c t·∫≠p
    - H∆∞·ªõng d·∫´n ghi nh·∫≠t k√Ω, vi·∫øt b√°o c√°o v√† s·ª≠ d·ª•ng bi·ªÉu m·∫´u
    - Ki·∫øn th·ª©c v·ªÅ vƒÉn h√≥a doanh nghi·ªáp CNTT, k·ªπ nƒÉng l√†m vi·ªác chuy√™n nghi·ªáp
    - T·ªïng quan v·ªÅ chuy·ªÉn ƒë·ªïi s·ªë, vai tr√≤ c·ªßa AI, d·ªØ li·ªáu v√† t·ª± ƒë·ªông h√≥a
    - G·ª£i √Ω ƒë·ªÅ t√†i th·ª±c t·∫ø t·∫°i doanh nghi·ªáp
    
    üìç Vui l√≤ng nh·∫≠p c√¢u h·ªèi b√™n d∆∞·ªõi ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ nhanh ch√≥ng, ch√≠nh x√°c v√† d·ªÖ hi·ªÉu.
    
    ---
    #### ‚ÑπÔ∏è Th√¥ng tin h·ªá th·ªëng
    - N·ªÅn t·∫£ng: Gemini + FAISS
    - Phi√™n b·∫£n: 1.0.0
    
    ---
    ¬© 2025 Khoa C√¥ng ngh·ªá Th√¥ng tin, ƒê·∫°i h·ªçc ƒê√¥ng √Å. M·ªçi quy·ªÅn ƒë∆∞·ª£c b·∫£o l∆∞u.
    """)
    
st.title("üéì Tutor AI - H·ªó tr·ª£ Th·ª±c t·∫≠p CNTT")
#st.caption("T√¨m ki·∫øm ng·ªØ c·∫£nh b·∫±ng FAISS & tr·∫£ l·ªùi v·ªõi Gemini 2.0")
with st.chat_message("assistant"):
    intro_text = """
    Xin ch√†o, t√¥i l√† **Tutor AI ‚Äì Tr·ª£ l√Ω ·∫£o ƒë·ªìng h√†nh c√πng b·∫°n trong k·ª≥ Th·ª±c t·∫≠p Nh·∫≠n Th·ª©c. T√¥i s·∫Ω h·ªó tr·ª£ b·∫°n trong su·ªët qu√° tr√¨nh th·ª±c t·∫≠p v·ªõi c√°c vai tr√≤:
    
    - Gi·∫£i ƒë√°p v·ªÅ n·ªôi dung, y√™u c·∫ßu v√† l·ªãch tr√¨nh th·ª±c t·∫≠p
    - H∆∞·ªõng d·∫´n c√°ch ghi **nh·∫≠t k√Ω**, vi·∫øt **b√°o c√°o**, s·ª≠ d·ª•ng **m·∫´u bi·ªÉu** ƒë√∫ng chu·∫©n
    - Cung c·∫•p ki·∫øn th·ª©c n·ªÅn t·∫£ng v·ªÅ **vƒÉn h√≥a doanh nghi·ªáp CNTT**, k·ªπ nƒÉng l√†m vi·ªác chuy√™n nghi·ªáp
    - Gi·ªõi thi·ªáu v·ªÅ **chuy·ªÉn ƒë·ªïi s·ªë trong doanh nghi·ªáp**, vai tr√≤ c·ªßa **AI, d·ªØ li·ªáu v√† t·ª± ƒë·ªông h√≥a**
    - G·ª£i √Ω v√† h∆∞·ªõng d·∫´n ƒë·ªÅ t√†i th·ª±c t·∫ø nh∆∞: ·ª©ng d·ª•ng AI h·ªó tr·ª£ nghi·ªáp v·ª•, chatbot n·ªôi b·ªô, qu·∫£n l√Ω t√†i li·ªáu s·ªë, ph√¢n t√≠ch d·ªØ li·ªáu kh√°ch h√†ng, h·ªá th·ªëng ph·∫£n h·ªìi th√¥ng minh...
    
    H√£y ƒë·∫∑t c√¢u h·ªèi b√™n d∆∞·ªõi ‚Äì t√¥i lu√¥n s·∫µn s√†ng h·ªó tr·ª£ b·∫°n!
    """
    
    # Hi·ªÉn th·ªã ph·∫ßn gi·ªõi thi·ªáu
    st.markdown(intro_text)
    
    # N·∫øu b·∫≠t √¢m thanh, ph√°t gi·ªõi thi·ªáu
    if st.session_state.get("enable_audio_playback", False):
        render_audio_block(intro_text, autoplay=True)

# Kh·ªüi t·∫°o session state ƒë·ªÉ l∆∞u l·ªãch s·ª≠ chat
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Nh·∫≠p c√¢u h·ªèi
#query = st.text_input("‚ùì Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:")
query = st.chat_input("‚ùì Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:")


if query:
    # C√°ch 1: Truy xu·∫•t ng·ªØ c·∫£nh li√™n quan
    # docs = vectorstore.similarity_search(query, k=8)
    # context = "\n".join([doc.page_content for doc in docs])
    
    #c√°ch 2:----------------------------
    # from deep_translator import GoogleTranslator
    # from langdetect import detect

    # lang = detect(query)

    # if lang == "vi":
    #     en_query = GoogleTranslator(source='vi', target='en').translate(query)
    # else:
    #     en_query = query  # ƒë√£ l√† ti·∫øng Anh

    # # docs = vectorstore.similarity_search(en_query, k=8)
    # # context = "\n".join([doc.page_content for doc in docs])
    
    # #c√°ch 3:----------------------------
    # docs_vi = vectorstore.similarity_search(query, k=4)
    # query_en = GoogleTranslator(source="vi", target="en").translate(query)
    # docs_en = vectorstore.similarity_search(query_en, k=4)

    # # K·∫øt h·ª£p lo·∫°i b·ªè tr√πng
    # context = "\n\n".join({doc.page_content for doc in docs_vi + docs_en})
    
    #c√°ch 4:----------------------------
    from deep_translator import GoogleTranslator
    from langdetect import detect

    # 1. Ph√°t hi·ªán ng√¥n ng·ªØ c√¢u h·ªèi g·ªëc
    lang = detect(query)

    # 2. Lu√¥n t·∫°o c·∫£ 2 b·∫£n: VI v√† EN
    if lang == "vi":
        query_vi = query
        query_en = GoogleTranslator(source="vi", target="en").translate(query)
    else:
        query_en = query
        query_vi = GoogleTranslator(source="en", target="vi").translate(query)

    # 3. Truy xu·∫•t context t·ª´ c·∫£ 2 c√¢u h·ªèi
    docs_vi = vectorstore.similarity_search(query_vi, k=8) #4
    docs_en = vectorstore.similarity_search(query_en, k=8) #4
    # print("üü© Context t·ª´ ti·∫øng Vi·ªát:")
    # for doc in docs_vi:
    #     print(doc.page_content)

    # print("\nüü¶ Context t·ª´ ti·∫øng Anh:")
    # for doc in docs_en:
    #     print(doc.page_content)
    
    # 4. Gh√©p c·∫£ 2 context (kh√¥ng lo·∫°i b·ªè tr√πng)
    #context = "\n\n".join({doc.page_content for doc in docs_vi + docs_en})
    
    top_k_docs = docs_vi + docs_en
    #reranked = rerank_with_crossencoder(query_vi, top_k_docs)
    # Truy v·∫•n ti·∫øng Vi·ªát + ti·∫øng Anh
    reranked_vi = rerank_with_crossencoder(query_vi, top_k_docs)
    reranked_en = rerank_with_crossencoder(query_en, top_k_docs)

    #L·∫•y ri√™ng t·ª´ng ph·∫ßn top 3 + top 3
    top_3_vi = sorted(reranked_vi, key=lambda x: x[0], reverse=True)[:3]
    top_3_en = sorted(reranked_en, key=lambda x: x[0], reverse=True)[:3]


    # G·ªôp v√† ch·ªçn top-k
    # combined = reranked_vi + reranked_en
    # combined = sorted(combined, key=lambda x: x[0], reverse=True)

    # context = "\n\n".join([chunk for _, chunk in combined[:3]])
    
    combined = top_3_vi + top_3_en
    context = "\n\n".join([chunk for _, chunk in combined])

    # In log ki·ªÉm tra
    for i, (score, text) in enumerate(combined):
        print(f"üî• TOP {i+1} ‚Äì Score: {score:.3f}")
        #print(text[:300], "\n")
        print(text, "\n")

    # T·∫°o prompt cho Gemini
    #T·∫°o history_summary tr∆∞·ªõc khi t·∫°o prompt
    history_summary = summarize_chat_history(st.session_state.chat_history, max_turns=2)
    
    prompt = f"""
    # Vai tr√≤: B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¢n thi·ªán, ƒëang h·ªó tr·ª£ sinh vi√™n nƒÉm 2 ng√†nh CNTT trong k·ª≥ th·ª±c t·∫≠p.

    # Ng·ªØ c·∫£nh: D∆∞·ªõi ƒë√¢y l√† ph·∫ßn h·ªôi tho·∫°i g·∫ßn ƒë√¢y gi·ªØa sinh vi√™n v√† b·∫°n:
        - {history_summary}

    # Y√™u c·∫ßu ƒë·∫ßu ra: H√£y tr·∫£ l·ªùi c√¢u h·ªèi d∆∞·ªõi ƒë√¢y d·ª±a tr√™n th√¥ng tin t√†i li·ªáu n·∫øu c√≥:
        - Gi·∫£i th√≠ch r√µ r√†ng, d·ªÖ hi·ªÉu
        - Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
        - N·∫øu th√¥ng tin c√≥ c·∫£ ti·∫øng Anh v√† ti·∫øng Vi·ªát, b·∫°n c√≥ th·ªÉ k·∫øt h·ª£p c·∫£ hai
        - Tr√°nh t·ª´ chuy√™n m√¥n n·∫øu kh√¥ng c·∫ßn thi·∫øt; n·∫øu c√≥, h√£y gi·∫£i th√≠ch th√™m ho·∫∑c ƒë∆∞a v√≠ d·ª• minh h·ªça
        - ∆Øu ti√™n s·ª≠ d·ª•ng th√¥ng tin t·ª´ t√†i li·ªáu tham kh·∫£o n·∫øu c√≥ li√™n quan
        - N·∫øu th√¥ng tin trong t√†i li·ªáu kh√¥ng ƒë·ªß ho·∫∑c kh√¥ng r√µ, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng ki·∫øn th·ª©c n·ªÅn t·∫£ng t·ª´ b√™n ngo√†i ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi ph√π h·ª£p v√† ch√≠nh x√°c
        - ƒê·∫£m b·∫£o c√¢u tr·∫£ l·ªùi kh√¥ng v∆∞·ª£t qu√° 1000 k√Ω t·ª±
        - Tr√°nh l·∫∑p l·∫°i l·ªùi ch√†o ho·∫∑c m·ªü ƒë·∫ßu nh∆∞ "Ch√†o b·∫°n", "R·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£..." ‚Äì h√£y ƒëi th·∫≥ng v√†o n·ªôi dung ch√≠nh.

    # Ng·ªØ c·∫£nh truy xu·∫•t t·ª´ t√†i li·ªáu:
        - {context}

    # C√¢u h·ªèi c·ªßa sinh vi√™n:
        - {query}
    """


    # G·ª≠i prompt ƒë·∫øn Gemini
    response = model.generate_content(prompt)
    answer = response.text.strip()

    # L∆∞u l·ªãch s·ª≠ Q&A
    st.session_state.chat_history.append({
        "question": query,
        "answer": answer
    })

# Hi·ªÉn th·ªã l·ªãch s·ª≠ h·ªôi tho·∫°i (m·ªõi nh·∫•t ·ªü d∆∞·ªõi c√πng)
for chat in st.session_state.chat_history:
    with st.chat_message("user"):
        st.markdown(chat["question"])
    with st.chat_message("ai"):
        st.markdown(chat["answer"])
        if st.session_state.get("enable_audio_playback", False):
            #render_audio_block(chat["answer"], autoplay=True)
            render_audio_block(chat["answer"], autoplay=st.session_state.get("enable_audio_playback", False))

