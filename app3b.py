import streamlit as st
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import TextLoader
import os

st.set_page_config(page_title="RAG Chatbot", page_icon="ğŸ¤–")

st.title("ğŸ¤– RAG Chatbot - HuggingFace + Gemini LLM")
st.info("Nháº­p cÃ¢u há»i sau khi upload file vÄƒn báº£n (.txt)")

# Láº¥y API key tá»« streamlit secrets
GOOGLE_API_KEY = st.secrets.get("GEMINI_API_KEY")
if not GOOGLE_API_KEY:
    st.error("Thiáº¿u API key trong settings. Vui lÃ²ng Ä‘áº·t GEMINI_API_KEY.")
    st.stop()

# Upload file
uploaded_file = st.file_uploader("ğŸ“ Táº£i file vÄƒn báº£n (.txt)", type=["txt"])

question = st.text_input("ğŸ’¬ Nháº­p cÃ¢u há»i:")

if uploaded_file and question:
    try:
        st.info("ğŸ“„ Äang xá»­ lÃ½ file...")
        docs = TextLoader(uploaded_file).load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        chunks = text_splitter.split_documents(docs)

        st.info("ğŸ“¡ Äang táº¡o FAISS vector DB...")
        embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        vectordb = FAISS.from_documents(chunks, embedding)

        retriever = vectordb.as_retriever()
        context_docs = retriever.get_relevant_documents(question)
        context = "\n".join(doc.page_content for doc in context_docs)

        prompt = f"Tráº£ lá»i dá»±a vÃ o ná»™i dung sau:\n---\n{context}\n---\nCÃ¢u há»i: {question}"

        llm = ChatGoogleGenerativeAI(model="gemini-pro", google_api_key=GOOGLE_API_KEY)
        st.info("ğŸ¤– Äang táº¡o cÃ¢u tráº£ lá»i...")
        answer = llm.invoke(prompt)
        st.success(answer)

    except Exception as e:
        st.error(f"âŒ Lá»—i: {e}")
