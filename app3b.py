import os
import streamlit as st
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.document_loaders import TextLoader

# C·∫•u h√¨nh m√¥i tr∆∞·ªùng
os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]
os.environ["STREAMLIT_WATCHER_TYPE"] = "none"

st.title("ü§ñ RAG Chatbot - HuggingFace + Gemini LLM")

uploaded_file = st.file_uploader("üìÅ T·∫£i file vƒÉn b·∫£n (.txt)", type="txt")

if uploaded_file:
    try:
        # L∆∞u file
        with open("data.txt", "wb") as f:
            f.write(uploaded_file.read())

        st.write("üìÑ ƒêang x·ª≠ l√Ω file...")

        # T√°ch vƒÉn b·∫£n
        loader = TextLoader("data.txt", encoding="utf-8")
        documents = loader.load()
        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        texts = splitter.split_documents(documents)

        # Kh·ªüi t·∫°o vector DB
        st.write("üì° ƒêang t·∫°o FAISS vector DB...")
        embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        db = FAISS.from_documents(texts, embedding)

        # Kh·ªüi t·∫°o m√¥ h√¨nh Gemini
        llm = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0.5)

        query = st.text_input("üí¨ Nh·∫≠p c√¢u h·ªèi:")
        if query:
            docs = db.similarity_search(query)
            context = "\n".join([doc.page_content for doc in docs])
            prompt = f"Tr·∫£ l·ªùi c√¢u h·ªèi sau d·ª±a v√†o ng·ªØ c·∫£nh:\n\n{context}\n\nC√¢u h·ªèi: {query}"
            response = llm.invoke(prompt)
            st.write("üß† Tr·∫£ l·ªùi:", response.content)

    except Exception as e:
        st.error(f"‚ùå L·ªói: {e}")
