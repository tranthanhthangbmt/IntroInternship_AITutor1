import os
import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.text_splitter import CharacterTextSplitter
from langchain.document_loaders import TextLoader

# Äáº£m báº£o khÃ³a API tá»“n táº¡i
GOOGLE_API_KEY = st.secrets.get("GOOGLE_API_KEY") or st.secrets.get("GEMINI_API_KEY")
if not GOOGLE_API_KEY:
    st.error("ğŸ”‘ GOOGLE_API_KEY chÆ°a Ä‘Æ°á»£c thiáº¿t láº­p trong Settings > Secrets!")
    st.stop()
os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY

# Giao diá»‡n ngÆ°á»i dÃ¹ng
st.title("ğŸ¤– RAG Chatbot - HuggingFace + Gemini LLM")
uploaded_file = st.file_uploader("ğŸ“ Táº£i file vÄƒn báº£n (.txt)", type="txt")

query = st.text_input("ğŸ’¬ Nháº­p cÃ¢u há»i:")

# Xá»­ lÃ½ khi cÃ³ file
if uploaded_file and query:
    try:
        st.info("ğŸ“„ Äang xá»­ lÃ½ file...")
        with open("temp.txt", "wb") as f:
            f.write(uploaded_file.getvalue())

        loader = TextLoader("temp.txt", encoding="utf-8")
        documents = loader.load()

        splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        docs = splitter.split_documents(documents)

        st.info("ğŸ“¡ Äang táº¡o FAISS vector DB...")
        embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        db = FAISS.from_documents(docs, embedding)

        retriever = db.as_retriever()
        llm = ChatGoogleGenerativeAI(model="gemini-pro", google_api_key=GOOGLE_API_KEY)

        st.success("âœ… Tráº£ lá»i:")
        result = llm.invoke(query)
        st.write(result.content)

    except Exception as e:
        st.error(f"âŒ Lá»—i: {e}")
