import streamlit as st
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.text_splitter import CharacterTextSplitter

import os

# Äá»c API key tá»« Streamlit secrets
GOOGLE_API_KEY = st.secrets.get("GEMINI_API_KEY", "")
if not GOOGLE_API_KEY:
    st.error("âŒ Thiáº¿u GEMINI_API_KEY trong Settings/Secrets")
    st.stop()

st.title("ğŸ¤– RAG Chatbot - HuggingFace + Gemini LLM")
st.markdown("### ğŸ“ Táº£i file vÄƒn báº£n (.txt)")
uploaded_file = st.file_uploader("Upload file", type=["txt"])

query = st.text_input("ğŸ’¬ Nháº­p cÃ¢u há»i:")

if uploaded_file and query:
    with st.spinner("ğŸ“„ Äang xá»­ lÃ½ file..."):
        text = uploaded_file.read().decode("utf-8")

        # Chia nhá» vÄƒn báº£n
        splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        texts = splitter.split_text(text)

        # Táº¡o embedding
        try:
            st.info("ğŸ“¡ Äang táº¡o FAISS vector DB...")
            embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
            vectordb = FAISS.from_texts(texts, embeddings)
        except Exception as e:
            st.error(f"âŒ Lá»—i táº¡o FAISS DB: {e}")
            st.stop()

        # Khá»Ÿi táº¡o LLM
        llm = ChatGoogleGenerativeAI(
            model="gemini-pro",
            google_api_key=GOOGLE_API_KEY,
            temperature=0.3
        )

        # TÃ¬m kiáº¿m ná»™i dung phÃ¹ há»£p nháº¥t
        docs = vectordb.similarity_search(query, k=3)
        context = "\n".join([doc.page_content for doc in docs])

        prompt = f"Dá»±a trÃªn Ä‘oáº¡n vÄƒn sau, hÃ£y tráº£ lá»i cÃ¢u há»i:\n\n{context}\n\nCÃ¢u há»i: {query}"
        try:
            answer = llm.invoke(prompt)
            st.success("ğŸ’¡ Tráº£ lá»i:")
            st.write(answer.content)
        except Exception as e:
            st.error(f"âŒ Lá»—i khi gá»i Gemini API: {e}")
