#run: streamlit run test_RAGStreamlit.py
import os
os.environ["STREAMLIT_WATCH_FILE_SYSTEM"] = "false"
import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from google.generativeai import GenerativeModel, configure

#audio
import edge_tts
from modules.audio_module import generate_and_encode_audio

def render_audio_block(text: str, autoplay=False):
    b64 = generate_and_encode_audio(text)
    autoplay_attr = "autoplay" if autoplay else ""
    st.markdown(f"""
    <audio controls {autoplay_attr}>
        <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
        TrÃ¬nh duyá»‡t cá»§a báº¡n khÃ´ng há»— trá»£ phÃ¡t Ã¢m thanh.
    </audio>
    """, unsafe_allow_html=True)

# âš ï¸ Cáº¥u hÃ¬nh API key Gemini (thay báº±ng key thá»±c táº¿ hoáº·c dÃ¹ng dotenv)
#configure(api_key="AIzaSyB23c7ttZ-RWiqj9O4dY82NutHsjz0N45s")
import streamlit as st
from google.generativeai import configure

configure(api_key=st.secrets["GEMINI_API_KEY"])
if "GEMINI_API_KEY" not in st.secrets:
    st.error("âŒ Thiáº¿u khÃ³a API Gemini. Vui lÃ²ng khai bÃ¡o trong Settings > Secrets.")
    st.stop()

# Khá»Ÿi táº¡o model Gemini
model = GenerativeModel("models/gemini-2.0-flash-lite")

# Load FAISS index
#embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2")
#embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-MiniLM-L3-v2")
embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2")


vectorstore = FAISS.load_local(
    "IntroInternshipRAG/faiss_index",
    embeddings=embedding,
    allow_dangerous_deserialization=True
)

# Cáº¥u hÃ¬nh giao diá»‡n Streamlit
st.set_page_config(page_title="Tutor AI â€“ Há»— trá»£ Thá»±c táº­p CNTT", page_icon="ğŸ“")
# Sidebar â€“ hiá»ƒn thá»‹ logo vÃ  thÃ´ng tin
with st.sidebar:
    st.image("https://raw.githubusercontent.com/tranthanhthangbmt/AITutor_Gemini/main/LOGO_UDA_2023_VN_EN_chuan2.png", width=180)
    if "enable_audio_playback" not in st.session_state:
        st.session_state["enable_audio_playback"] = True  # máº·c Ä‘á»‹nh báº­t
    
    st.session_state["enable_audio_playback"] = st.sidebar.checkbox(
        "ğŸ”Š Tá»± Ä‘á»™ng phÃ¡t Ã¢m thanh",
        value=st.session_state["enable_audio_playback"]
    )

    st.markdown("""
    ### ğŸ“ Tutor AI â€“ Äáº¡i há»c ÄÃ´ng Ã
    **Há»— trá»£ sinh viÃªn thá»±c táº­p ngÃ nh CNTT**

    ---
    ğŸ“ *Má»i tháº¯c máº¯c vui lÃ²ng nháº­p bÃªn dÆ°á»›i Ä‘á»ƒ Ä‘Æ°á»£c giáº£i Ä‘Ã¡p.*
    """)
    
st.title("ğŸ“ Tutor AI - Há»— trá»£ Thá»±c táº­p CNTT")
#st.caption("TÃ¬m kiáº¿m ngá»¯ cáº£nh báº±ng FAISS & tráº£ lá»i vá»›i Gemini 2.0")
with st.chat_message("assistant"):
    intro_text = """
    **Xin chÃ o!**
    
    TÃ´i lÃ  **Tutor AI** â€“ trá»£ lÃ½ áº£o Ä‘á»“ng hÃ nh cÃ¹ng sinh viÃªn trong quÃ¡ trÃ¬nh thá»±c hiá»‡n **Thá»±c táº­p Nháº­n Thá»©c ngÃ nh CÃ´ng nghá»‡ ThÃ´ng tin** táº¡i TrÆ°á»ng Äáº¡i há»c ÄÃ´ng Ã.
    
    Trong suá»‘t ká»³ thá»±c táº­p, tÃ´i sáº½ há»— trá»£ báº¡n:
    - Náº¯m rÃµ ná»™i dung, yÃªu cáº§u vÃ  lá»‹ch trÃ¬nh thá»±c táº­p
    - Ghi nháº­t kÃ½, viáº¿t bÃ¡o cÃ¡o Ä‘Ãºng chuáº©n vÃ  Ä‘áº§y Ä‘á»§
    - Hiá»ƒu rÃµ cÃ¡c máº«u biá»ƒu, quy trÃ¬nh Ä‘Ã¡nh giÃ¡, ká»¹ nÄƒng nghá» nghiá»‡p cáº§n cÃ³
    - Äá»‹nh hÆ°á»›ng vÃ  triá»ƒn khai bÃ i toÃ¡n thá»±c táº­p hiá»‡u quáº£
    
    HÃ£y nháº­p cÃ¢u há»i cá»§a báº¡n bÃªn dÆ°á»›i. TÃ´i luÃ´n sáºµn sÃ ng há»— trá»£!
    """


    
    # Hiá»ƒn thá»‹ pháº§n giá»›i thiá»‡u
    st.markdown(intro_text)
    
    # Náº¿u báº­t Ã¢m thanh, phÃ¡t giá»›i thiá»‡u
    if st.session_state.get("enable_audio_playback", False):
        render_audio_block(intro_text, autoplay=True)

# Khá»Ÿi táº¡o session state Ä‘á»ƒ lÆ°u lá»‹ch sá»­ chat
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Nháº­p cÃ¢u há»i
#query = st.text_input("â“ Nháº­p cÃ¢u há»i cá»§a báº¡n:")
query = st.chat_input("â“ Nháº­p cÃ¢u há»i cá»§a báº¡n:")


if query:
    # Truy xuáº¥t ngá»¯ cáº£nh liÃªn quan
    docs = vectorstore.similarity_search(query, k=6)
    context = "\n".join([doc.page_content for doc in docs])

    # Táº¡o prompt cho Gemini
    prompt = f"""
    Báº¡n lÃ  trá»£ lÃ½ AI Ä‘ang há»— trá»£ sinh viÃªn thá»±c táº­p CNTT.
    HÃ£y tráº£ lá»i cÃ¢u há»i dÆ°á»›i Ä‘Ã¢y má»™t cÃ¡ch chi tiáº¿t, chÃ­nh xÃ¡c vÃ  dá»… hiá»ƒu nháº¥t, dá»±a trÃªn cÃ¡c thÃ´ng tin cÃ³ trong tÃ i liá»‡u:

    Ngá»¯ cáº£nh:
    {context}

    CÃ¢u há»i:
    {query}
    """

    # Gá»­i prompt Ä‘áº¿n Gemini
    response = model.generate_content(prompt)
    answer = response.text.strip()

    # LÆ°u lá»‹ch sá»­ Q&A
    st.session_state.chat_history.append({
        "question": query,
        "answer": answer
    })

# Hiá»ƒn thá»‹ lá»‹ch sá»­ há»™i thoáº¡i (má»›i nháº¥t á»Ÿ dÆ°á»›i cÃ¹ng)
for chat in st.session_state.chat_history:
    with st.chat_message("user"):
        st.markdown(chat["question"])
    with st.chat_message("ai"):
        st.markdown(chat["answer"])
        if st.session_state.get("enable_audio_playback", False):
            render_audio_block(chat["answer"], autoplay=True)
