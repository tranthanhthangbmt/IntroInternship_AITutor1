#run: streamlit run test_RAGStreamlit.py
import os
os.environ["STREAMLIT_WATCH_FILE_SYSTEM"] = "false"
import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from google.generativeai import GenerativeModel, configure

#audio
import edge_tts
from modules.audio_module import generate_and_encode_audio

def render_audio_block(text: str, autoplay=False):
    b64 = generate_and_encode_audio(text)
    autoplay_attr = "autoplay" if autoplay else ""
    st.markdown(f"""
    <audio controls {autoplay_attr}>
        <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
        Tr√¨nh duy·ªát c·ªßa b·∫°n kh√¥ng h·ªó tr·ª£ ph√°t √¢m thanh.
    </audio>
    """, unsafe_allow_html=True)

# ‚ö†Ô∏è C·∫•u h√¨nh API key Gemini (thay b·∫±ng key th·ª±c t·∫ø ho·∫∑c d√πng dotenv)
#configure(api_key="AIzaSyB23c7ttZ-RWiqj9O4dY82NutHsjz0N45s")
import streamlit as st
from google.generativeai import configure

configure(api_key=st.secrets["GEMINI_API_KEY"])
if "GEMINI_API_KEY" not in st.secrets:
    st.error("‚ùå Thi·∫øu kh√≥a API Gemini. Vui l√≤ng khai b√°o trong Settings > Secrets.")
    st.stop()

# Kh·ªüi t·∫°o model Gemini
model = GenerativeModel("models/gemini-2.0-flash-lite")

# Load FAISS index
#embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2")
#embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-MiniLM-L3-v2")
embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2")


vectorstore = FAISS.load_local(
    "IntroInternshipRAG/faiss_index",
    embeddings=embedding,
    allow_dangerous_deserialization=True
)

# C·∫•u h√¨nh giao di·ªán Streamlit
st.set_page_config(page_title="Tutor AI ‚Äì H·ªó tr·ª£ Th·ª±c t·∫≠p CNTT", page_icon="üéì")
st.set_option("client.showErrorDetails", False)
# Sidebar ‚Äì hi·ªÉn th·ªã logo v√† th√¥ng tin
with st.sidebar:
    st.image("https://raw.githubusercontent.com/tranthanhthangbmt/AITutor_Gemini/main/LOGO_UDA_2023_VN_EN_chuan2.png", width=180)
    if "enable_audio_playback" not in st.session_state:
        st.session_state["enable_audio_playback"] = False  # m·∫∑c ƒë·ªãnh b·∫≠t
    
    st.session_state["enable_audio_playback"] = st.sidebar.checkbox(
        "üîä T·ª± ƒë·ªông ph√°t √¢m thanh",
        value=st.session_state["enable_audio_playback"]
    )

    st.markdown("""
    ### üéì Tutor AI ‚Äì ƒê·∫°i h·ªçc ƒê√¥ng √Å
    **H·ªó tr·ª£ sinh vi√™n th·ª±c t·∫≠p ng√†nh CNTT**

    ---
    üìç *M·ªçi th·∫Øc m·∫Øc vui l√≤ng nh·∫≠p b√™n d∆∞·ªõi ƒë·ªÉ ƒë∆∞·ª£c gi·∫£i ƒë√°p.*
    """)
    
st.title("üéì Tutor AI - H·ªó tr·ª£ Th·ª±c t·∫≠p CNTT")
#st.caption("T√¨m ki·∫øm ng·ªØ c·∫£nh b·∫±ng FAISS & tr·∫£ l·ªùi v·ªõi Gemini 2.0")
with st.chat_message("assistant"):
    intro_text = """
    Xin ch√†o, t√¥i l√† **Tutor AI ‚Äì Tr·ª£ l√Ω ·∫£o ƒë·ªìng h√†nh c√πng b·∫°n trong k·ª≥ Th·ª±c t·∫≠p Nh·∫≠n Th·ª©c. T√¥i s·∫Ω h·ªó tr·ª£ b·∫°n trong su·ªët qu√° tr√¨nh th·ª±c t·∫≠p v·ªõi c√°c vai tr√≤:
    
    - Gi·∫£i ƒë√°p v·ªÅ n·ªôi dung, y√™u c·∫ßu v√† l·ªãch tr√¨nh th·ª±c t·∫≠p
    - H∆∞·ªõng d·∫´n c√°ch ghi **nh·∫≠t k√Ω**, vi·∫øt **b√°o c√°o**, s·ª≠ d·ª•ng **m·∫´u bi·ªÉu** ƒë√∫ng chu·∫©n
    - Cung c·∫•p ki·∫øn th·ª©c n·ªÅn t·∫£ng v·ªÅ **vƒÉn h√≥a doanh nghi·ªáp CNTT**, k·ªπ nƒÉng l√†m vi·ªác chuy√™n nghi·ªáp
    - Gi·ªõi thi·ªáu v·ªÅ **chuy·ªÉn ƒë·ªïi s·ªë trong doanh nghi·ªáp**, vai tr√≤ c·ªßa **AI, d·ªØ li·ªáu v√† t·ª± ƒë·ªông h√≥a**
    - G·ª£i √Ω v√† h∆∞·ªõng d·∫´n ƒë·ªÅ t√†i th·ª±c t·∫ø nh∆∞: ·ª©ng d·ª•ng AI h·ªó tr·ª£ nghi·ªáp v·ª•, chatbot n·ªôi b·ªô, qu·∫£n l√Ω t√†i li·ªáu s·ªë, ph√¢n t√≠ch d·ªØ li·ªáu kh√°ch h√†ng, h·ªá th·ªëng ph·∫£n h·ªìi th√¥ng minh...
    
    H√£y ƒë·∫∑t c√¢u h·ªèi b√™n d∆∞·ªõi ‚Äì t√¥i lu√¥n s·∫µn s√†ng h·ªó tr·ª£ b·∫°n!
    """
    
    # Hi·ªÉn th·ªã ph·∫ßn gi·ªõi thi·ªáu
    st.markdown(intro_text)
    
    # N·∫øu b·∫≠t √¢m thanh, ph√°t gi·ªõi thi·ªáu
    if st.session_state.get("enable_audio_playback", False):
        render_audio_block(intro_text, autoplay=True)

# Kh·ªüi t·∫°o session state ƒë·ªÉ l∆∞u l·ªãch s·ª≠ chat
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Nh·∫≠p c√¢u h·ªèi
#query = st.text_input("‚ùì Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:")
query = st.chat_input("‚ùì Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:")


if query:
    # Truy xu·∫•t ng·ªØ c·∫£nh li√™n quan
    docs = vectorstore.similarity_search(query, k=3)
    context = "\n".join([doc.page_content for doc in docs])

    # T·∫°o prompt cho Gemini
    prompt = f"""
    B·∫°n l√† tr·ª£ l√Ω AI d√†nh cho sinh vi√™n CNTT. 
    H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn, r√µ r√†ng v√† th·ª±c t·∫ø, ch·ªâ t·∫≠p trung v√†o √Ω ch√≠nh trong ng·ªØ c·∫£nh sau:
    
    Ng·ªØ c·∫£nh:
    {context}
    
    C√¢u h·ªèi:
    {query}
    """

    # G·ª≠i prompt ƒë·∫øn Gemini
    response = model.generate_content(prompt)
    answer = response.text.strip()

    # L∆∞u l·ªãch s·ª≠ Q&A
    st.session_state.chat_history.append({
        "question": query,
        "answer": answer
    })

# Hi·ªÉn th·ªã l·ªãch s·ª≠ h·ªôi tho·∫°i (m·ªõi nh·∫•t ·ªü d∆∞·ªõi c√πng)
for chat in st.session_state.chat_history:
    with st.chat_message("user"):
        st.markdown(chat["question"])
    with st.chat_message("ai"):
        st.markdown(chat["answer"])
        if st.session_state.get("enable_audio_playback", False):
            render_audio_block(chat["answer"], autoplay=True)
