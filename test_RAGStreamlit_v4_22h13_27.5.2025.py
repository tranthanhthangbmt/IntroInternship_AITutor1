#versions:
# test_RAGStreamlit_v3_10h56_27.5.2025.py s·ª≠a l·∫°i audio cho streamlit local
#test_RAGStreamlit_v3C_15h13_27.5.2025.py s·ª≠ l·∫°i ph·∫ßu t·∫£i file RAG t·ª´ Google Drive
#test_RAGStreamlit_v4_22h13_27.5.2025.py: hu·∫•n luy·ªán ti·∫øng Anh, h·ªèi b·∫±ng ti·∫øng Vi·ªát
#---------------------------
#run: streamlit run test_RAGStreamlit_v4_22h13_27.5.2025.py
#run2: streamlit run --server.fileWatcherType none test_RAGStreamlit_v4_22h13_27.5.2025.py
#------------------

# import os
# os.environ["STREAMLIT_WATCH_FILE_SYSTEM"] = "false"
import asyncio
try:
    asyncio.get_running_loop()
except RuntimeError:
    asyncio.set_event_loop(asyncio.new_event_loop())
    
import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from google.generativeai import GenerativeModel, configure

#audio
import edge_tts
#from modules.audio_module import generate_and_encode_audio
from modules.audio_module import render_audio_block



# ‚ö†Ô∏è C·∫•u h√¨nh API key Gemini (thay b·∫±ng key th·ª±c t·∫ø ho·∫∑c d√πng dotenv)
#configure(api_key="AIzaSyB23c7ttZ-RWiqj9O4dY82NutHsjz0N45s")

import streamlit as st
from google.generativeai import configure

configure(api_key=st.secrets["GEMINI_API_KEY"])
if "GEMINI_API_KEY" not in st.secrets:
    st.error("‚ùå Thi·∫øu kh√≥a API Gemini. Vui l√≤ng khai b√°o trong Settings > Secrets.")
    st.stop()

# import time

# long_text = "Xin ch√†o, t√¥i l√† Tutor AI..." * 30  # t·∫°o ƒëo·∫°n d√†i
# start = time.time()
# b64 = generate_and_encode_audio(long_text)
# print("Th·ªùi gian t·∫°o √¢m:", time.time() - start)

# Kh·ªüi t·∫°o model Gemini
model = GenerativeModel("models/gemini-2.0-flash-lite")

import os
import gdown

# T·∫°o ƒëo·∫°n m√£ Python t·∫£i th∆∞ m·ª•c FAISS t·ª´ Google Drive
# if not os.path.exists("IntroInternshipRAG_MiniLM_L3_withEbooks/faiss_index"):
#     gdown.download_folder(
#         url="https://drive.google.com/drive/folders/1GZF0Aas4n7m1kkd-MmoCGyR7oH77xXWE",
#         output="IntroInternshipRAG_MiniLM_L3_withEbooks",
#         quiet=False,
#         use_cookies=False
#     )


if not os.path.exists("IntroInternshipRAG_MiniLM_L3_allRef/faiss_index"):
    gdown.download_folder(
        url="https://drive.google.com/drive/folders/13tzW43t7MuqtOP8-xYy-7lRYgEgtNTVX",
        output="IntroInternshipRAG_MiniLM_L3_allRef",
        quiet=False,
        use_cookies=False
    )

# D√πng m√¥ h√¨nh nh·ªè h∆°n
embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-MiniLM-L3-v2")

# Load FAISS index t·ª´ th∆∞ m·ª•c m·ªõi
DATA_OUTPUT_FOLDER = "IntroInternshipRAG_MiniLM_L3_allRef"
vectorstore = FAISS.load_local(
    #"IntroInternshipRAG_MiniLM_L3/faiss_index",
    DATA_OUTPUT_FOLDER+ "/faiss_index",
    embeddings=embedding,
    allow_dangerous_deserialization=True
)

def summarize_chat_history(history, max_turns=3):
    if not history:
        return ""

    recent_turns = history[-max_turns:]
    summary = ""
    for turn in recent_turns:
        summary += f"Sinh vi√™n: {turn['question']}\n"
        summary += f"Tutor: {turn['answer']}\n"
    return summary.strip()
    
# C·∫•u h√¨nh giao di·ªán Streamlit
st.set_page_config(page_title="Tutor AI ‚Äì H·ªó tr·ª£ Th·ª±c t·∫≠p CNTT", page_icon="üéì")
st.set_option("client.showErrorDetails", False)
# Sidebar ‚Äì hi·ªÉn th·ªã logo v√† th√¥ng tin
with st.sidebar:
    st.image("https://raw.githubusercontent.com/tranthanhthangbmt/AITutor_Gemini/main/LOGO_UDA_2023_VN_EN_chuan2.png", width=180)
    if "enable_audio_playback" not in st.session_state:
        st.session_state["enable_audio_playback"] = True  # m·∫∑c ƒë·ªãnh b·∫≠t
    
    st.session_state["enable_audio_playback"] = st.sidebar.checkbox(
        "üîä T·ª± ƒë·ªông ph√°t √¢m thanh",
        value=st.session_state["enable_audio_playback"]
    )

    st.markdown("""
    ### üéì Tutor AI ‚Äì ƒê·∫°i h·ªçc ƒê√¥ng √Å
    **H·ªó tr·ª£ sinh vi√™n th·ª±c t·∫≠p ng√†nh CNTT**

    ---
    üìç *M·ªçi th·∫Øc m·∫Øc vui l√≤ng nh·∫≠p b√™n d∆∞·ªõi ƒë·ªÉ ƒë∆∞·ª£c gi·∫£i ƒë√°p.*
    """)
    
st.title("üéì Tutor AI - H·ªó tr·ª£ Th·ª±c t·∫≠p CNTT")
#st.caption("T√¨m ki·∫øm ng·ªØ c·∫£nh b·∫±ng FAISS & tr·∫£ l·ªùi v·ªõi Gemini 2.0")
with st.chat_message("assistant"):
    intro_text = """
    Xin ch√†o, t√¥i l√† **Tutor AI ‚Äì Tr·ª£ l√Ω ·∫£o ƒë·ªìng h√†nh c√πng b·∫°n trong k·ª≥ Th·ª±c t·∫≠p Nh·∫≠n Th·ª©c. T√¥i s·∫Ω h·ªó tr·ª£ b·∫°n trong su·ªët qu√° tr√¨nh th·ª±c t·∫≠p v·ªõi c√°c vai tr√≤:
    
    - Gi·∫£i ƒë√°p v·ªÅ n·ªôi dung, y√™u c·∫ßu v√† l·ªãch tr√¨nh th·ª±c t·∫≠p
    - H∆∞·ªõng d·∫´n c√°ch ghi **nh·∫≠t k√Ω**, vi·∫øt **b√°o c√°o**, s·ª≠ d·ª•ng **m·∫´u bi·ªÉu** ƒë√∫ng chu·∫©n
    - Cung c·∫•p ki·∫øn th·ª©c n·ªÅn t·∫£ng v·ªÅ **vƒÉn h√≥a doanh nghi·ªáp CNTT**, k·ªπ nƒÉng l√†m vi·ªác chuy√™n nghi·ªáp
    - Gi·ªõi thi·ªáu v·ªÅ **chuy·ªÉn ƒë·ªïi s·ªë trong doanh nghi·ªáp**, vai tr√≤ c·ªßa **AI, d·ªØ li·ªáu v√† t·ª± ƒë·ªông h√≥a**
    - G·ª£i √Ω v√† h∆∞·ªõng d·∫´n ƒë·ªÅ t√†i th·ª±c t·∫ø nh∆∞: ·ª©ng d·ª•ng AI h·ªó tr·ª£ nghi·ªáp v·ª•, chatbot n·ªôi b·ªô, qu·∫£n l√Ω t√†i li·ªáu s·ªë, ph√¢n t√≠ch d·ªØ li·ªáu kh√°ch h√†ng, h·ªá th·ªëng ph·∫£n h·ªìi th√¥ng minh...
    
    H√£y ƒë·∫∑t c√¢u h·ªèi b√™n d∆∞·ªõi ‚Äì t√¥i lu√¥n s·∫µn s√†ng h·ªó tr·ª£ b·∫°n!
    """
    
    # Hi·ªÉn th·ªã ph·∫ßn gi·ªõi thi·ªáu
    st.markdown(intro_text)
    
    # N·∫øu b·∫≠t √¢m thanh, ph√°t gi·ªõi thi·ªáu
    # if st.session_state.get("enable_audio_playback", False):
    #     render_audio_block(intro_text, autoplay=True)

# Kh·ªüi t·∫°o session state ƒë·ªÉ l∆∞u l·ªãch s·ª≠ chat
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Nh·∫≠p c√¢u h·ªèi
#query = st.text_input("‚ùì Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:")
query = st.chat_input("‚ùì Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:")


if query:
    # C√°ch 1: Truy xu·∫•t ng·ªØ c·∫£nh li√™n quan
    # docs = vectorstore.similarity_search(query, k=8)
    # context = "\n".join([doc.page_content for doc in docs])
    
    #c√°ch 2:----------------------------
    # from deep_translator import GoogleTranslator
    # from langdetect import detect

    # lang = detect(query)

    # if lang == "vi":
    #     en_query = GoogleTranslator(source='vi', target='en').translate(query)
    # else:
    #     en_query = query  # ƒë√£ l√† ti·∫øng Anh

    # # docs = vectorstore.similarity_search(en_query, k=8)
    # # context = "\n".join([doc.page_content for doc in docs])
    
    # #c√°ch 3:----------------------------
    # docs_vi = vectorstore.similarity_search(query, k=4)
    # query_en = GoogleTranslator(source="vi", target="en").translate(query)
    # docs_en = vectorstore.similarity_search(query_en, k=4)

    # # K·∫øt h·ª£p lo·∫°i b·ªè tr√πng
    # context = "\n\n".join({doc.page_content for doc in docs_vi + docs_en})
    
    #c√°ch 4:----------------------------
    from deep_translator import GoogleTranslator
    from langdetect import detect

    # 1. Ph√°t hi·ªán ng√¥n ng·ªØ c√¢u h·ªèi g·ªëc
    lang = detect(query)

    # 2. Lu√¥n t·∫°o c·∫£ 2 b·∫£n: VI v√† EN
    if lang == "vi":
        query_vi = query
        query_en = GoogleTranslator(source="vi", target="en").translate(query)
    else:
        query_en = query
        query_vi = GoogleTranslator(source="en", target="vi").translate(query)

    # 3. Truy xu·∫•t context t·ª´ c·∫£ 2 c√¢u h·ªèi
    docs_vi = vectorstore.similarity_search(query_vi, k=4)
    docs_en = vectorstore.similarity_search(query_en, k=4)
    # print("üü© Context t·ª´ ti·∫øng Vi·ªát:")
    # for doc in docs_vi:
    #     print(doc.page_content)

    # print("\nüü¶ Context t·ª´ ti·∫øng Anh:")
    # for doc in docs_en:
    #     print(doc.page_content)
    
    # 4. Gh√©p c·∫£ 2 context (kh√¥ng lo·∫°i b·ªè tr√πng)
    # context_vi = "\n\n".join([f"[VI]\n{doc.page_content}" for doc in docs_vi])
    # context_en = "\n\n".join([f"[EN]\n{doc.page_content}" for doc in docs_en])
    # context = f"{context_vi}\n\n{context_en}"
    context = "\n\n".join({doc.page_content for doc in docs_vi + docs_en})

    #T·∫°o history_summary tr∆∞·ªõc khi t·∫°o prompt
    history_summary = summarize_chat_history(st.session_state.chat_history, max_turns=2)
    
    prompt = f"""
    B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¢n thi·ªán, ƒëang h·ªó tr·ª£ sinh vi√™n nƒÉm 2 ng√†nh CNTT trong k·ª≥ th·ª±c t·∫≠p.
    D∆∞·ªõi ƒë√¢y l√† ph·∫ßn h·ªôi tho·∫°i g·∫ßn ƒë√¢y gi·ªØa sinh vi√™n v√† b·∫°n:
    {history_summary}
    
    H√£y tr·∫£ l·ªùi c√¢u h·ªèi d∆∞·ªõi ƒë√¢y d·ª±a tr√™n th√¥ng tin t√†i li·ªáu n·∫øu c√≥:
    - Gi·∫£i th√≠ch r√µ r√†ng, d·ªÖ hi·ªÉu
    - Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
    - N·∫øu th√¥ng tin c√≥ c·∫£ ti·∫øng Anh v√† ti·∫øng Vi·ªát, b·∫°n c√≥ th·ªÉ k·∫øt h·ª£p c·∫£ hai
    - Tr√°nh t·ª´ chuy√™n m√¥n n·∫øu kh√¥ng c·∫ßn thi·∫øt; n·∫øu c√≥, h√£y gi·∫£i th√≠ch th√™m ho·∫∑c ƒë∆∞a v√≠ d·ª• minh h·ªça
    - ∆Øu ti√™n s·ª≠ d·ª•ng th√¥ng tin t·ª´ t√†i li·ªáu tham kh·∫£o n·∫øu c√≥ li√™n quan
    - N·∫øu th√¥ng tin trong t√†i li·ªáu kh√¥ng ƒë·ªß ho·∫∑c kh√¥ng r√µ, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng ki·∫øn th·ª©c n·ªÅn t·∫£ng t·ª´ b√™n ngo√†i ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi ph√π h·ª£p v√† ch√≠nh x√°c
    - ƒê·∫£m b·∫£o c√¢u tr·∫£ l·ªùi kh√¥ng v∆∞·ª£t qu√° 700 k√Ω t·ª± (t∆∞∆°ng ƒë∆∞∆°ng 1 ph√∫t ƒë·ªçc)
    
    Tr√°nh l·∫∑p l·∫°i l·ªùi ch√†o ho·∫∑c m·ªü ƒë·∫ßu nh∆∞ "Ch√†o b·∫°n", "R·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£..." ‚Äì h√£y ƒëi th·∫≥ng v√†o n·ªôi dung ch√≠nh.

    Ng·ªØ c·∫£nh truy xu·∫•t t·ª´ t√†i li·ªáu:
    {context}

    C√¢u h·ªèi c·ªßa sinh vi√™n:
    {query}
    """

    # G·ª≠i prompt ƒë·∫øn Gemini
    response = model.generate_content(prompt)
    answer = response.text.strip()

    # L∆∞u l·ªãch s·ª≠ Q&A
    st.session_state.chat_history.append({
        "question": query,
        "answer": answer
    })

# Hi·ªÉn th·ªã l·ªãch s·ª≠ h·ªôi tho·∫°i (m·ªõi nh·∫•t ·ªü d∆∞·ªõi c√πng)
for chat in st.session_state.chat_history:
    with st.chat_message("user"):
        st.markdown(chat["question"])
    with st.chat_message("ai"):
        st.markdown(chat["answer"])
        if st.session_state.get("enable_audio_playback", False):
            #render_audio_block(chat["answer"], autoplay=True)
            render_audio_block(chat["answer"], autoplay=st.session_state.get("enable_audio_playback", False))

